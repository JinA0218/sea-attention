{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'torch1 (Python 3.9.16)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOSPC: no space left on device, close"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import argparse\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from typing import List, Tuple, Optional\n",
    "from matplotlib import cm\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'torch1 (Python 3.9.16)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOSPC: no space left on device, close"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "module_path = \"/d1/jinakim/permutation-learning/src/\"\n",
    "sys.path.append(module_path)\n",
    "\n",
    "from utils import batch_to\n",
    "from models import hf_bert as bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'torch1 (Python 3.9.16)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOSPC: no space left on device, close"
     ]
    }
   ],
   "source": [
    "TASK_TO_VALID = {\n",
    "    \"cola\": \"validation\",\n",
    "    \"mnli\": \"validation_matched\",\n",
    "    \"mrpc\": \"test\",\n",
    "    \"qnli\": \"validation\",\n",
    "    \"qqp\": \"validation\",\n",
    "    \"rte\": \"validation\",\n",
    "    \"sst2\": \"validation\",\n",
    "    \"stsb\": \"validation\",\n",
    "    \"wnli\": \"validation\",\n",
    "    \"bert\": \"validation\",\n",
    "}\n",
    "\n",
    "TASK_TO_KEYS = {\n",
    "    \"cola\": (\"sentence\", None),\n",
    "    \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "    \"qnli\": (\"question\", \"sentence\"),\n",
    "    \"qqp\": (\"question1\", \"question2\"),\n",
    "    \"rte\": (\"sentence1\", \"sentence2\"),\n",
    "    \"sst2\": (\"sentence\", None),\n",
    "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "    \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'torch1 (Python 3.9.16)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOSPC: no space left on device, close"
     ]
    }
   ],
   "source": [
    "from models import hf_bert as berts\n",
    "import transformers\n",
    "\n",
    "def get_base_model(dataset, only_tokenizer=False):\n",
    "    checkpoint = {\n",
    "        \"cola\": \"textattack/bert-base-uncased-CoLA\",\n",
    "        \"mnli\": \"yoshitomo-matsubara/bert-base-uncased-mnli\",\n",
    "        \"mrpc\": \"textattack/bert-base-uncased-MRPC\",\n",
    "        # \"mrpc\": \"M-FAC/bert-tiny-finetuned-mrpc\",\n",
    "        \"qnli\": \"textattack/bert-base-uncased-QNLI\",\n",
    "        \"qqp\": \"textattack/bert-base-uncased-QQP\",\n",
    "        \"rte\": \"textattack/bert-base-uncased-RTE\",\n",
    "        \"sst2\": \"textattack/bert-base-uncased-SST-2\",\n",
    "        \"stsb\": \"textattack/bert-base-uncased-STS-B\",\n",
    "        \"wnli\": \"textattack/bert-base-uncased-WNLI\",\n",
    "        \"bert\": \"bert-base-uncased\",\n",
    "    }[dataset]\n",
    "\n",
    "    # NOTE(HJ): this bert models has special hooks\n",
    "    model = {\n",
    "        \"cola\": berts.BertForSequenceClassification,\n",
    "        \"mnli\": berts.BertForSequenceClassification,\n",
    "        \"mrpc\": berts.BertForSequenceClassification,\n",
    "        \"qnli\": berts.BertForSequenceClassification,\n",
    "        \"qqp\": berts.BertForSequenceClassification,\n",
    "        \"rte\": berts.BertForSequenceClassification,\n",
    "        \"sst2\": berts.BertForSequenceClassification,\n",
    "        \"stsb\": berts.BertForSequenceClassification,\n",
    "        \"wnli\": berts.BertForSequenceClassification,\n",
    "        \"bert\": berts.BertForSequenceClassification,\n",
    "    }[dataset]\n",
    "    \n",
    "    tokenizer = transformers.BertTokenizerFast.from_pretrained(checkpoint)\n",
    "    if only_tokenizer:\n",
    "        return None, tokenizer\n",
    "    \n",
    "    bert = model.from_pretrained(checkpoint, cache_dir='./cache/huggingface/')\n",
    "    return bert, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'torch1 (Python 3.9.16)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOSPC: no space left on device, close"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "import random, torch\n",
    "\n",
    "def get_dataloader(subset, tokenizer, batch_size, split='train', encode_batch_size=384):\n",
    "    if subset == 'bert':\n",
    "        subset = \"cola\" #return dummy set\n",
    "    \n",
    "    dataset = load_dataset('glue', subset, split=split, cache_dir='./cache/datasets')\n",
    "    \n",
    "    sentence1_key, sentence2_key = TASK_TO_KEYS[subset]\n",
    "\n",
    "    def encode(examples):\n",
    "        # Tokenize the texts\n",
    "        args = (\n",
    "            (examples[sentence1_key],) if sentence2_key is None else (examples[sentence1_key], examples[sentence2_key])\n",
    "        )\n",
    "        result = tokenizer(*args, padding=True, max_length=256, truncation=True)\n",
    "        # result = tokenizer(*args, padding=\"max_length\", max_length=512, truncation=True)\n",
    "        # Map labels to IDs (not necessary for GLUE tasks)\n",
    "        # if label_to_id is not None and \"label\" in examples:\n",
    "        #     result[\"label\"] = [(label_to_id[l] if l != -1 else -1) for l in examples[\"label\"]]\n",
    "        return result\n",
    "    \n",
    "    if split.startswith('train'): #shuffle when train set\n",
    "        dataset = dataset.sort('label')\n",
    "        dataset = dataset.shuffle(seed=random.randint(0, 10000))\n",
    "    dataset = dataset.map(lambda examples: {'labels': examples['label']}, batched=True, batch_size=encode_batch_size)\n",
    "    dataset = dataset.map(encode, batched=True, batch_size=encode_batch_size)\n",
    "    dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        num_workers=0,\n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'torch1 (Python 3.9.16)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOSPC: no space left on device, close"
     ]
    }
   ],
   "source": [
    "def gather_fixed_batch(dataloader: DataLoader, batch_size: int):\n",
    "    items = [\n",
    "        dataloader.dataset.__getitem__(i * (len(dataloader.dataset) // batch_size))\n",
    "        for i in range(batch_size)\n",
    "    ]\n",
    "    max_len = max([it['input_ids'].shape[0] for it in items])\n",
    "    for it in items:\n",
    "        it['input_ids'] = F.pad(it['input_ids'], (0, max_len-len(it['input_ids'])))\n",
    "        it['attention_mask'] = F.pad(it['attention_mask'], (0, max_len-len(it['attention_mask'])))\n",
    "        it['token_type_ids'] = F.pad(it['token_type_ids'], (0, max_len-len(it['token_type_ids'])))\n",
    "    # print([[(k, v.shape) for k, v in it.items()] for it in items])\n",
    "    return dataloader.collate_fn(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'torch1 (Python 3.9.16)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOSPC: no space left on device, close"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "BF16 = torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
    "\n",
    "N, H, T, T_M =16, 12, 203, 128\n",
    "subset = \"mnli\"\n",
    "\n",
    "base_model, tokenizer = get_base_model(subset)\n",
    "base_model.to(device=0)\n",
    "\n",
    "loader = get_dataloader(subset, tokenizer, N, split=TASK_TO_VALID[subset])\n",
    "batch = gather_fixed_batch(loader, N)\n",
    "batch = batch_to(batch, device=0)\n",
    "\n",
    "base_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    base_model(**batch)\n",
    "\n",
    "for module in base_model.modules():\n",
    "    if isinstance(module, bert.BertSelfAttention):\n",
    "        teacher_score = module.perlin_last_attention_score\n",
    "        teacher_probs = module.perlin_last_attention_prob\n",
    "        teacher_context_layer = module.perlin_last_context_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'torch1 (Python 3.9.16)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOSPC: no space left on device, close"
     ]
    }
   ],
   "source": [
    "teacher_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
